{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI & COVID - TEXAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The CDC's social vulnerability index (SVI) is a scale that predicts the vulnerability of a population in the event of an emergency or natural disaster. COVID is the first global pandemic since the development of this measure. We will evaluate the association between SVI score and COVID case count in Texas. Features from this measure will be incorporated into a predictive model that can be used to guide recovery resource prioritization.\n",
    "\n",
    "\n",
    "\n",
    "**Goals**      \n",
    "1. Evaluate association between SVI score and COVID case count across counties in TX     \n",
    "2. Build a model based SVI score component features that can predict COVID cases per 100k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scripts_python import wrangle\n",
    "from scripts_python import explore\n",
    "from scripts_python import model_MAE\n",
    "from scripts_python import acquire_all_counties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFE \n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import sqrt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire & Prepare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check acquire function\n",
    "df = acquire_all_counties.get_countylevelonly_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check prepare function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the requested date in YYYY-MM-DD format: 2021-01-05\n",
      "Enter the requested state full name: texas\n",
      "(254, 123)\n",
      "(254, 6)\n",
      "(254, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1467e572ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrangle_countylevelonly_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/side_projects/COVID/svi_capstone/scripts_python/wrangle.py\u001b[0m in \u001b[0;36mwrangle_countylevelonly_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tract_cases_per_100k'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mtrain_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/side_projects/COVID/svi_capstone/scripts_python/wrangle.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(df, target_var)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# split df into train (80%) and test (20%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# cross validation with be used instead of a validate dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_svi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# for explore create copy of train without x/y split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2131\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1814\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1815\u001b[0m         )\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "df, train_exp, X_train_scaled, y_train, X_test_scaled, y_test = wrangle.wrangle_countylevelonly_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "Exploration focuses on answering questions regarding the relationship between the CDC's range category SVI score and cases of COVID-19 per 100k.\n",
    "\n",
    "- Visualize cases per 100K by binned SVI value\n",
    "    - Appear to be distinct\n",
    "    - Will conduct parametric ANOCA (Kruskal) test to confirm\n",
    "- Verify raw SVI score relationship to cases per 100K\n",
    "    - will conduct Pearson's R correlation test\n",
    "- Explore distribution of casses per 100K with SVI score\n",
    "- Explore distribution of flags by SVI score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "### Question One: Is there a correlation between the CDC's Range Category SVI Score and COVID-19 Infection Cases per 100k Individuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.sns_boxplot(train_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`There appears to be a correlation between COVID-19 Count and SVI Category. Next step is Hypothesis testing between categories to validate statistical significance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean COVID-19 Count By CDC's SVI Category\n",
    "All = round(train_exp.tract_cases_per_100k.mean(),5)\n",
    "low = round((train_exp[train_exp.bin_svi == 'Low']).tract_cases_per_100k.mean(),5)\n",
    "low_mod = round((train_exp[train_exp.bin_svi == 'Low Moderate']).tract_cases_per_100k.mean(),6)\n",
    "mod_high = round((train_exp[train_exp.bin_svi == 'Moderate High']).tract_cases_per_100k.mean(),6)\n",
    "high = round((train_exp[train_exp.bin_svi== 'High']).tract_cases_per_100k.mean(),6)\n",
    "\n",
    "print(f'The average number of cases per 100k for all CDC SVI Range Categories is {All}') \n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (low) is {low}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (low_mod) is {low_mod}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (mod_high) is {mod_high}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (high) is {high}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = (train_exp[train_exp.bin_svi == 'Low']).tract_cases_per_100k\n",
    "low_mod = (train_exp[train_exp.bin_svi == 'Low Moderate']).tract_cases_per_100k\n",
    "mod_high = (train_exp[train_exp.bin_svi == 'Moderate High']).tract_cases_per_100k\n",
    "high = (train_exp[train_exp.bin_svi== 'High']).tract_cases_per_100k\n",
    "alpha = 0.01\n",
    "null = \"Average number of COVID-19 cases per 100k is the same across all CDC SVI Range Categories \"\n",
    "alternate = \"Average number of COVID-19 cases per 100k is significantly different across all CDC SVI Range Categories \"\n",
    "explore.kruskal_test(low, low_mod, mod_high, high, null, alternate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`We can state with 99% certainty that there is a statistically significant difference between all of the CDC SVI Range Categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Two: Is there a correlation between raw_svi and cases per 100k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_svi = train_exp.raw_svi\n",
    "cases_per_100k = train_exp.tract_cases_per_100k\n",
    "alpha = 0.01\n",
    "null = \"There is no statistically significant difference betweeen raw_svi and cases per 100K \"\n",
    "alternate = \"There is a statistically significant difference betweeen raw_svi and cases per 100K\"\n",
    "explore.pearson(raw_svi, cases_per_100k, null, alternate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`We can state with 99% certainty that there is not a statistically significant difference between the Social Vulnerability Index and Census Tract cases per 100,000 people.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.joint_plot_index('raw_svi','tract_cases_per_100k', train_exp, 'bin_svi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.my_plotter(train_exp, 'all_flags_total', \"Education Level\", 'tract_cases_per_100k', \"Cases by Tract per 100k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-run explore.py to get this to update. Works in my notebook.\n",
    "\n",
    "explore.hist_case_title(train_exp.tract_cases_per_100k, \"Distribution of Cases in Dallas, TX: December 8th 2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "- Baseline for modeling determined by plotting the histogram distribution of COVID-19 cases per 100k.\n",
    "- The skew observed in the distribution led us to use the median for this value instead of the mean??\n",
    "- Used cross validation due to limited size of dataset. Size of dataset limited by Dallas number of census tracts.\n",
    "- Three of the 4 models used all of the features in the dataset, one model used only the top4 features identified by RFE.\n",
    "- Linear Regression, LassoLars, and 2 degree polynomial features used all features and a 2nd version of 2 degree polynomial was run with just the top4 features.\n",
    "- Of these the LassoLars had the least MAE (mean absolute error) and was run on out of sample data (test).\n",
    "- This model had nearly identical MAE when run on out of sample data, only a 0.7 difference in MAE.\n",
    "- Overall this is a 25% improvement from mean baseline MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean vs median of the target variable?\n",
    "y_train.tract_cases_per_100k.mean(), y_train.tract_cases_per_100k.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean absolute error (MAE) of the baseline using mean\n",
    "mean_baseMAE, basepred1 = model_MAE.get_baseline_mean(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ranking\n",
    "\n",
    "- Use recursive feature elimination to evaluate features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdf = model_MAE.feature_ranking(X_train_scaled, y_train)\n",
    "rankdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only raw svi score\n",
    "X_raw_svi = X_train_scaled[['raw_svi']]\n",
    "# binned svi score by CDC range category = 1st ranked\n",
    "X_rank_svi_only = X_train_scaled[['rank_svi_scaled']]\n",
    "# top 4 ranked features\n",
    "X_top4 = X_train_scaled[['raw_svi', 'rank_svi_scaled', 'f_munit_trans', 'f_mobile_trans']]\n",
    "# only the summary of the flags = 19th ranked\n",
    "X_all_flags_only = X_train_scaled[['all_flags_total_scaled']]\n",
    "# only summary flags, should be the same as all flags total? = 5th, 12th, 15th, 21st\n",
    "X_summary_flags = X_train_scaled[['f_comp_total_scaled', 'f_soci_total_scaled', 'f_status_total_scaled', 'f_trans_total_scaled']]\n",
    "# all individual flags\n",
    "X_not_summary_flags = X_train_scaled[['f_nohsdp_soci', 'f_minrty_status', 'f_groupq_trans', 'f_unemp_soci', \n",
    "                                     'f_disabl_comp', 'f_noveh_trans', 'f_mobile_trans', 'f_age65_comp', \n",
    "                                     'f_age17_comp', 'f_pov_soci', 'f_limeng_status', 'f_crowd_trans', \n",
    "                                      'f_pci_soci', 'f_sngpnt_comp', 'f_munit_trans']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models\n",
    "\n",
    "- due to limited size of dataset (limited by number of zip codes in Dallas county) cross validation will be used for the train and validate stages of modeling\n",
    "- regression models will be used because the target variable is continuous\n",
    "- models to try: linear regression, LassoLars, Tweedie Regressor Random Forest Regressor, Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "# create variables for loop\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# Linear Regression Models\n",
    "cvlm_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvlm_MAE = model_MAE.cvLinearReg(df, target) \n",
    "    cvlm_MAE_list.append(cvlm_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Lars\n",
    "# create variables for loop\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# LassoLars Models\n",
    "cvll_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvll_MAE = model_MAE.cvLassoLars(df, target, 1) \n",
    "    cvll_MAE_list.append(cvll_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, send in x scaled, y train, and # estimators\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# Random Forest Models\n",
    "cvrf_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvrf_MAE = model_MAE.cvRandomForest(df, target, 4) \n",
    "    cvrf_MAE_list.append(cvrf_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweedie Regressor, send in x scaled, y train, power and alpha settings\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# Tweedie Regressor Models\n",
    "cvtw_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvtw_MAE = model_MAE.cvTweedie(df, target, 1.5, .5)\n",
    "    cvtw_MAE_list.append(cvtw_MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor, send in x scaled, y train, kernel = 'rbf' or 'linear'\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# Support Vector Models\n",
    "cvSVRrbf_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvSVRrbf_MAE = model_MAE.cvSVR(df, target, 'rbf')\n",
    "    cvSVRrbf_MAE_list.append(cvSVRrbf_MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor, send in x scaled, y train, kernel = 'rbf' or 'linear'\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, X_raw_svi]\n",
    "target = y_train\n",
    "\n",
    "# Support Vector Models\n",
    "cvSVRlinear_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvSVRlinear_MAE = model_MAE.cvSVR(df, target, 'linear')\n",
    "    cvSVRlinear_MAE_list.append(cvSVRlinear_MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for results of all train models\n",
    "df_list = ['rank_svi_only', 'top4', 'total_all_flags_only', 'summary_flags', 'not_summary_flags', 'all_features', 'raw_svi_only']\n",
    "\n",
    "results = pd.DataFrame(df_list, columns=['Features'])\n",
    "results['Base_mean_MAE'] = mean_baseMAE\n",
    "results['LinearRegression_MAE'] = cvlm_MAE_list\n",
    "results['LassoLars_MAE'] = cvll_MAE_list\n",
    "results['Tweedie_MAE'] = cvtw_MAE_list\n",
    "results['RandomForest_MAE'] = cvrf_MAE_list\n",
    "results['SVR_rbf_MAE'] = cvSVRrbf_MAE_list\n",
    "results['SVR_linear_MAE'] = cvSVRlinear_MAE_list\n",
    "results.sort_values('LinearRegression_MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataframe with only the not summary flags features as that is the best performing model\n",
    "X_test_not_sflg = X_test_scaled[['f_nohsdp_soci', 'f_minrty_status', 'f_groupq_trans', 'f_unemp_soci', \n",
    "                                     'f_disabl_comp', 'f_noveh_trans', 'f_mobile_trans', 'f_age65_comp', \n",
    "                                     'f_age17_comp', 'f_pov_soci', 'f_limeng_status', 'f_crowd_trans', \n",
    "                                      'f_pci_soci', 'f_sngpnt_comp', 'f_munit_trans']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear Regression with Top4 features on train dataset, then use that model to predict test values\n",
    "LRtestMAE, modelLR = model_MAE.linear_test(X_not_summary_flags, y_train, X_test_not_sflg, y_test)\n",
    "LRtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWtestMAE, modelTW = model_MAE.tweedie_test(X_not_summary_flags, y_train, X_test_not_sflg, y_test, 1.5, .5)\n",
    "TWtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLtestMAE, modelLL = model_MAE.lasso_lars_test(X_not_summary_flags, y_train, X_test_not_sflg, y_test)\n",
    "LLtestMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Metrics in Context    \n",
    "\n",
    "- All models performed worse than baseline on test\n",
    "- SVI and features do not seem to correlate as closely with high case rates in Dallas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LassoLars Summary:\n",
    "\n",
    "LASSO = Least Absolute Shrinkage and Selection Operator\n",
    "LARS = Least Angle Regression\n",
    "\n",
    "LASSO + LARS performs both feature selection (LASSO) and noise reduction within the same model. If the target variable (Y) is normally distributed. As alpha increases, the efficiency of the model features taper off as indicated in the graph. The features only add a fixed amount of benefit to the model, but once alpha reaches a certain point, the benefit derived from a particular features plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSOLARS Results table:\n",
    "ll_result = pd.DataFrame()\n",
    "x_train_columns = X_test_top4.columns.tolist()\n",
    "ll_result['features'] = x_train_columns\n",
    "ll_result['coefs'] = modelLL.coef_\n",
    "ll_result['abs_coefs'] = abs(modelLL.coef_)\n",
    "ll_result.sort_values(by = 'abs_coefs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weaknesses\n",
    "\n",
    "- There is no consensus in research literature as to which components of the SVI have the strongest correlation to health risks or outcomes. There are some demographic groups requiring careful interpretation of the results due to their unique characteristics.\n",
    "- These models are not intended in any way to be presented as predictions of infection; the medical reasons for COVID transmission are still as yet undetermined, and would require a vastly more complex model than is presented here. The purpose of this model was to measure and predict those areas most in need of help and response from communities and local officials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps: What Can We Do Now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Dallas different from other cities?\n",
    "\n",
    "- Dallas is very different from San Antonio\n",
    "- SVI and features do not seem to correlate as closely with high case rates in Dallas (unlike in San Antonio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- SVI trend for the county\n",
    "    - is rising? is declining? \n",
    "    - delta of SVI change year over year?\n",
    "    - std dev of SVI?\n",
    "\n",
    "- This is an area for possible further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
