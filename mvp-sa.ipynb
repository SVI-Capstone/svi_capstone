{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVI & COVID - SAN ANTONIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The CDC's social vulnerability index (SVI) is a scale that predicts the vulnerability of a population in the event of an emergency or natural disaster. COVID is the first global pandemic since the development of this measure. We will evaluate the association between SVI score and COVID case count in San Antonio, Texas. Features from this measure will be incorporated into a predictive model that can be used to guide recovery resource prioritization.\n",
    "\n",
    "\n",
    "\n",
    "**Goals**      \n",
    "1. Evaluate association between SVI score and COVID case count in San Antonio, TX     \n",
    "2. Build a model based SVI score component features that can predict COVID cases by census tract within San Antonio, TX\n",
    "3. Complete same evaluation and models for Dallas\n",
    "4. Is there a difference between San Antonio and Dallas results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Background\n",
    "The SVI (Social Vulnerability Index) was developed to help city governments and first responders predict areas that are particularly vulnerable in emergency situations so that resources can be prioritized to help areas at high risk (Citation CDC Website). The CDC’s Social Vulnerability Index (CDC SVI) uses 15 U.S. census variables to classify census tracts with a composite score between 0 and 1 (lower scores = less vulnerability, higher score = greater vulnerability. This socre is calculated by first ranking every census tract, in every country, in every state, in the United States. Those ranked tracks are then broken up to 4 themes (socioeconomic status, household composition and disability, minority status and language, household type and transportation) and reclassified. This overall score is then tallied by summing the themed percentiles and ranked on a score between 0 and 1.\n",
    "\n",
    "While SVI was designed to help city goverments repsond to emergency situations, the efficacy of the systems has never been tested on in response to a global pandemic. COVID-19 is the disease caused by a new coronavirus called SARS-CoV-2. WHO first learned of this new virus on 31 December 2019, following a report of a cluster of cases of ‘viral pneumonia’ in Wuhan, People’s Republic of China. (Citation WHO). As of 9 December 2020, more than 68.4 million cases have been confirmed, with more than 1.56 million deaths attributed to COVID-19.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Plan\n",
    "\n",
    "*Now that you have a clear idea of what you are trying to accomplish, you need to find a data source. Think of this as working through a maze forwards and backwards at the same time. At the start you have any number of data sets available to work with (and the whole Internet to search and scrape), and at the end is the hypothetical data set that would answer your question immediately if you had it.*\n",
    "\n",
    "- What data, if you had it, would solve your problem right away?\n",
    "    - Cases count per 100K by census tract nationally would be ideal\n",
    "- What data do you have access to?\n",
    "    - Have SVI from CDC by census track\n",
    "    - Have Bexar county case count per 100K by zip code for single date 12/8/20\n",
    "- What additional data would be good to have?\n",
    "    - be great to have more historical data\n",
    "- What data would be impossible to collect?\n",
    "    - due to privacy/panic concerns case data at the census tract level is not being published for open access\n",
    "- What are the best proxies you can find for unavailable or impossible data?\n",
    "    - find a way to translate from census tract to zip code\n",
    "- What are the legal or ethical issues you might run into if you were to try to collect all of the types of data you would like to work with?\n",
    "    - considered web scraping for zip code level data where specific information is not available\n",
    "    - likely better to hard code existing data that is publicly available\n",
    "\n",
    "*Of course you need to make a plan to turn your data into the solutions you need. Think of what type of problem this is, what models are commonly used for those types of problems, what types of data those models require and special considerations that may need to be made. Do your homework and find out what approaches other people are using on similar tasks.*\n",
    "\n",
    "- What ML paradigm are you working in? (Classification, Regression, Clustering, etc)\n",
    "    - Regression\n",
    "- What models are commonly used in this task?\n",
    "    - Linear Regression, LassoLars, Polynomial Features, Tweedie Regressor\n",
    "* What other solutions are being tried in this field?\n",
    "* What special considerations need to be taken when dealing with these models? (i.e., imbalanced classes, text preprocessing, data leakage, etc)\n",
    "* How will you know that your models work?\n",
    "* How will you recognize and diagnose cases where the predictions are incorrect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scripts_python import acquire\n",
    "# from .scripts_python import explore\n",
    "# from .scripts_python import model_MAE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from statsmodels.formula.api import ols\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "# from sklearn.feature_selection import f_regression, SelectKBest, RFE \n",
    "# from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# # Classfication Modeling:\n",
    "# from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "# import model_classification\n",
    "\n",
    "# from math import sqrt\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_san_antonio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>population</th>\n",
       "      <th>positive</th>\n",
       "      <th>casesp100000</th>\n",
       "      <th>zipint</th>\n",
       "      <th>activecases</th>\n",
       "      <th>activecaserate</th>\n",
       "      <th>shape_length</th>\n",
       "      <th>shape_area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBJECTID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78002</td>\n",
       "      <td>9061</td>\n",
       "      <td>378</td>\n",
       "      <td>4171.724975</td>\n",
       "      <td>78002</td>\n",
       "      <td>24</td>\n",
       "      <td>264.871427</td>\n",
       "      <td>0.427542</td>\n",
       "      <td>0.009546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78006</td>\n",
       "      <td>5243</td>\n",
       "      <td>96</td>\n",
       "      <td>1831.012779</td>\n",
       "      <td>78006</td>\n",
       "      <td>7</td>\n",
       "      <td>133.511348</td>\n",
       "      <td>0.552725</td>\n",
       "      <td>0.005416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78015</td>\n",
       "      <td>12254</td>\n",
       "      <td>192</td>\n",
       "      <td>1566.835319</td>\n",
       "      <td>78015</td>\n",
       "      <td>16</td>\n",
       "      <td>130.569610</td>\n",
       "      <td>0.278955</td>\n",
       "      <td>0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78023</td>\n",
       "      <td>29569</td>\n",
       "      <td>642</td>\n",
       "      <td>2171.192803</td>\n",
       "      <td>78023</td>\n",
       "      <td>49</td>\n",
       "      <td>165.714092</td>\n",
       "      <td>0.886455</td>\n",
       "      <td>0.017922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78052</td>\n",
       "      <td>699</td>\n",
       "      <td>28</td>\n",
       "      <td>4005.722461</td>\n",
       "      <td>78052</td>\n",
       "      <td>1</td>\n",
       "      <td>143.061516</td>\n",
       "      <td>0.260085</td>\n",
       "      <td>0.001147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zip  population  positive  casesp100000  zipint  activecases  \\\n",
       "OBJECTID                                                                   \n",
       "1         78002        9061       378   4171.724975   78002           24   \n",
       "2         78006        5243        96   1831.012779   78006            7   \n",
       "4         78015       12254       192   1566.835319   78015           16   \n",
       "5         78023       29569       642   2171.192803   78023           49   \n",
       "7         78052         699        28   4005.722461   78052            1   \n",
       "\n",
       "          activecaserate  shape_length  shape_area  \n",
       "OBJECTID                                            \n",
       "1             264.871427      0.427542    0.009546  \n",
       "2             133.511348      0.552725    0.005416  \n",
       "4             130.569610      0.278955    0.002312  \n",
       "5             165.714092      0.886455    0.017922  \n",
       "7             143.061516      0.260085    0.001147  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire & Prepare\n",
    "\n",
    "- SVI data from the CDC's website\n",
    "- downloaded COVID data for San Antonio and Dallas from the cities respective COVID data web portals\n",
    "- HUD crosswalk provided a guide to transform the data\n",
    "    - complicated because of overlap in census tracts and zip codes\n",
    "    - found the Zip code that accounted for the highest percentage of addresses within the tract and assigned that as the sole Zip code for the tract\n",
    "    - the ratio of addresses for the census tract was then used to calculate a cases per 100K measure for each tract \n",
    "- selected 29 features and renamed for clarity\n",
    "- verified no null values to address\n",
    "- military bases were removed from the data frame\n",
    "- raw SVI score binned\n",
    "    - bin_svi column = text label (low, low-mod, mod-high, high)\n",
    "    - rank_svi column = numeric representation of SVI (1 representing a high score, 4 representing a low score)\n",
    "- numeric columns with values greater than 4 were scaled using sklearn's MinMaxScaler\n",
    "- six data frames returned at then end of wrangle including *train_explore* for exploration and individual scaled data frames for modeling  *X_train_scaled, y_train, X_test_scaled, y_test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train_exp, X_train_scaled, y_train, X_test_scaled, y_test = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "Exploration focuses on answering questions regarding the relationship between the CDC's range category SVI score and cases of COVID-19 per 100k.\n",
    "\n",
    "- Visualize cases per 100K by binned SVI value\n",
    "    - Appear to be distinct\n",
    "    - Will conduct parametric ANOCA (Kruskal) test to confirm\n",
    "- Verify raw SVI score relationship to cases per 100K\n",
    "    - will conduct Pearson's R correlation test\n",
    "- Explore distribution of casses per 100K with SVI score\n",
    "- Explore distribution of flags by SVI score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "### Question One: Is there a correlation between the CDC's Range Category SVI Score and COVID-19 Infection Cases per 100k Individuals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.sns_boxplot(train_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`There appears to be a correlation between COVID-19 Count and SVI Category. Next step is Hypothesis testing between categories to validate statistical significance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean COVID-19 Count By CDC's SVI Category\n",
    "All = round(train_exp.tract_cases_per_100k.mean(),5)\n",
    "low = round((train_exp[train_exp.bin_svi == 'Low']).tract_cases_per_100k.mean(),5)\n",
    "low_mod = round((train_exp[train_exp.bin_svi == 'Low Moderate']).tract_cases_per_100k.mean(),6)\n",
    "mod_high = round((train_exp[train_exp.bin_svi == 'Moderate High']).tract_cases_per_100k.mean(),6)\n",
    "high = round((train_exp[train_exp.bin_svi== 'High']).tract_cases_per_100k.mean(),6)\n",
    "\n",
    "print(f'The average number of cases per 100k for all CDC SVI Range Categories is {All}') \n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (low) is {low}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (low_mod) is {low_mod}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (mod_high) is {mod_high}')\n",
    "print(f'The average number of cases per 100k for CDC SVI Range Category (high) is {high}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = (train_exp[train_exp.bin_svi == 'Low']).tract_cases_per_100k\n",
    "low_mod = (train_exp[train_exp.bin_svi == 'Low Moderate']).tract_cases_per_100k\n",
    "mod_high = (train_exp[train_exp.bin_svi == 'Moderate High']).tract_cases_per_100k\n",
    "high = (train_exp[train_exp.bin_svi== 'High']).tract_cases_per_100k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(low, low_mod, mod_high, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "null = \"Average number of COVID-19 cases per 100k is the same across all CDC SVI Range Categories \"\n",
    "alternate = \"Average number of COVID-19 cases per 100k is significantly different across all CDC SVI Range Categories \"\n",
    "explore.anova_test(low, low_mod, mod_high, high, null, alternate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`We can state with 99% certainty that there is a statistically significant difference between all of the CDC SVI Range Categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Two: Is there a correlation between raw_svi and cases per 100k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_svi = train_exp.raw_svi\n",
    "cases_per_100k = train_exp.tract_cases_per_100k\n",
    "alpha = 0.01\n",
    "null = \"There is no statistically significant difference betweeen raw_svi and cases per 100K \"\n",
    "alternate = \"There is a statistically significant difference betweeen raw_svi and cases per 100K\"\n",
    "explore.pearson(raw_svi, cases_per_100k, null, alternate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "`We can state with 99% certainty that there is not a statistically significant difference between the Social Vulnerability Index and Census Tract cases per 100,000 people.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.joint_plot_index('raw_svi','tract_cases_per_100k', train_exp, 'bin_svi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.my_plotter(train_exp, \"all_flags_total\", \"All SVI Component Flags\", \"tract_cases_per_100k\", \"Cases by Tract per 100k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.hist_case(train_exp.tract_cases_per_100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore: Feature Engineering (Clustering)\n",
    "\n",
    "Features that demonstrate potential for Clustering\n",
    "\n",
    "1. E_POV (Persons below poverty estimate)\n",
    "2. EP_POV (Percentage of persons below poverty estimate)\n",
    "3. SPL_THEME1 (Sum of series for Socioeconomic theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot spl_theme1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.cluster_scatter(train_exp, \n",
    "                'Sum of Flags for Socioeconomic Themes by Number of Cases per 100k', \n",
    "                'spl_theme1',\n",
    "                'Sum of Flags for Socioeconomic Themes',\n",
    "                'tract_cases_per_100k',\n",
    "                'Number of Cases per 100,000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot e_pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.cluster_scatter(train_exp, \n",
    "                'Persons Below Poverty Estimate by Number of Cases per 100k', \n",
    "                'e_pov',\n",
    "                'Persons Below Poverty Estimate',\n",
    "                'tract_cases_per_100k',\n",
    "                'Number of Cases per 100,000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatterplot ep_pov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.cluster_scatter(train_exp, \n",
    "                'Percentage of Persons Below Poverty Estimate by Number of Cases per 100k', \n",
    "                'ep_pov',\n",
    "                'Percentage of Persons Below Poverty Estimate',\n",
    "                'tract_cases_per_100k',\n",
    "                'Number of Cases per 100,000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Poverty Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow Method to establish k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_vars = ['spl_theme1_scaled', 'ep_pov_scaled', 'e_pov_scaled']\n",
    "explore.elbow_plot(X_train_scaled, cluster_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusters, kmeans = explore.run_kmeans(train_exp, X_train_scaled, k=3, cluster_vars=cluster_vars, cluster_col_name = 'poverty_cluster')\n",
    "test_clusters = explore.kmeans_transform(X_test_scaled, kmeans, cluster_vars, cluster_col_name = 'poverty_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = explore.get_centroids(cluster_vars, cluster_col_name='poverty_cluster', kmeans= kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append Cluster and Join Centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exp = explore.add_to_train(train_clusters, centroids, train_exp, cluster_col_name = 'poverty_cluster')\n",
    "X_train_scaled = explore.add_to_train(train_clusters, centroids, X_train_scaled, cluster_col_name = 'poverty_cluster')\n",
    "X_test_scaled = explore.add_to_train(test_clusters, centroids, X_test_scaled, cluster_col_name = 'poverty_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the clusters significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.sns_boxplot_hypothesis(train_exp.poverty_cluster, \n",
    "                       train_exp.tract_cases_per_100k, \n",
    "                       \"Poverty Clusters\", \n",
    "                       \"Cases per 100k\", \n",
    "                       \"Are The Clusters Significant?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hypothesis Testing: (ANOVA/Kruskal)\n",
    "\n",
    "Is there a statistically significant difference between poverty_clusters and cases per 100k?\n",
    "\n",
    "Null Hypothesis: Mean # of cases is the same across all clusters\n",
    "\n",
    "Alternative Hypothesis: Mean # of cases is different across clusters\n",
    "\n",
    "alpha=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_0 = train_exp[train_exp.poverty_cluster == 0].tract_cases_per_100k\n",
    "cluster_1 = train_exp[train_exp.poverty_cluster == 1].tract_cases_per_100k\n",
    "cluster_2 = train_exp[train_exp.poverty_cluster == 2].tract_cases_per_100k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(cluster_0, cluster_1, cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "null = \"Mean number of cases per 100k is the same across all clusters\"\n",
    "alternate = \"Average number of cases per 100k is significantly different between clusters\"\n",
    "explore.anova_test(low, low_mod, mod_high, high, null, alternate, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split clusters in to dummy variables for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.get_dummies(X_train_scaled,\n",
    "                           columns=[\"poverty_cluster\"])\n",
    "X_test_scaled = pd.get_dummies(X_test_scaled,\n",
    "                           columns=[\"poverty_cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "- Baseline for modeling determined by plotting the histogram distribution of COVID-19 cases per 100k.\n",
    "- The skew observed in the distribution led us to use the median for this value instead of the mean??\n",
    "- Used cross validation due to limited size of dataset. Size of dataset limited by San Antonio number of census tracts.\n",
    "- Three of the 4 models used all of the features in the dataset, one model used only the top4 features identified by RFE.\n",
    "- Linear Regression, LassoLars, and 2 degree polynomial features used all features and a 2nd version of 2 degree polynomial was run with just the top4 features.\n",
    "- Of these the LassoLars had the least MAE (mean absolute error) and was run on out of sample data (test).\n",
    "- This model had nearly identical MAE when run on out of sample data, only a 0.7 difference in MAE.\n",
    "- Overall this is a 25% improvement from mean baseline MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean vs median of the target variable?\n",
    "y_train.tract_cases_per_100k.mean(), y_train.tract_cases_per_100k.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean absolute error (MAE) of the baseline using mean\n",
    "mean_baseMAE, basepred1 = model_MAE.get_baseline_mean(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ranking\n",
    "\n",
    "- Use recursive feature elimination to evaluate features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdf = model_MAE.feature_ranking(X_train_scaled, y_train)\n",
    "rankdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only raw svi score\n",
    "X_raw_svi = X_train_scaled[['raw_svi']]\n",
    "# binned svi score by CDC range category = 1st ranked\n",
    "X_rank_svi_only = X_train_scaled[['rank_svi_scaled']]\n",
    "# top 4 ranked features\n",
    "X_top4 = X_train_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr']]\n",
    "# only the summary of the flags = 19th ranked\n",
    "X_all_flags_only = X_train_scaled[['all_flags_total_scaled']]\n",
    "# only summary flags, should be the same as all flags total? = 5th, 12th, 15th, 21st\n",
    "X_summary_flags = X_train_scaled[['f_comp_total_scaled', 'f_soci_total_scaled', 'f_status_total_scaled', 'f_trans_total_scaled']]\n",
    "# all individual flags\n",
    "X_not_summary_flags = X_train_scaled[['f_nohsdp_soci', 'f_minrty_status', 'f_groupq_trans', 'f_unemp_soci', \n",
    "                                     'f_disabl_comp', 'f_noveh_trans', 'f_mobile_trans', 'f_age65_comp', \n",
    "                                     'f_age17_comp', 'f_pov_soci', 'f_limeng_status', 'f_crowd_trans', \n",
    "                                      'f_pci_soci', 'f_sngpnt_comp', 'f_munit_trans']]\n",
    "# top 10 by RFE\n",
    "X_top10 = X_train_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr', 'rank_svi_scaled', \n",
    "                          'f_soci_total_scaled', 'f_pov_soci', 'ep_pov_scaled', 'raw_svi', 'f_age17_comp']]\n",
    "# engineered features only\n",
    "X_svifeatures = X_train_scaled[['rising', 'falling', 'delta', 'avg3yr', 'r_soci_rise', 'r_comp_rise', \n",
    "                                'r_status_rise', 'r_trans_rise', 'r_soci_fall', 'r_comp_fall', 'r_status_fall', 'r_trans_fall']]\n",
    "X_Rlist = X_train_scaled[['rank_svi_scaled', 'rising', 'falling', 'delta', 'avg3yr']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Regression Models\n",
    "\n",
    "- due to limited size of dataset (limited by number of zip codes in San Antonio area) cross validation will be used for the train and validate stages of modeling\n",
    "- regression models will be used because the target variable is continuous\n",
    "- models to try: linear regression, LassoLars, Tweedie Regressor Random Forest Regressor, Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for loop\n",
    "df2test = [X_rank_svi_only, X_top4, X_all_flags_only, X_summary_flags, X_not_summary_flags, X_train_scaled, \n",
    "           X_raw_svi, X_top10, X_svifeatures, X_Rlist]\n",
    "target = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Models\n",
    "cvlm_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvlm_MAE = model_MAE.cvLinearReg(df, target) \n",
    "    cvlm_MAE_list.append(cvlm_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoLars Models\n",
    "cvll_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvll_MAE = model_MAE.cvLassoLars(df, target, 1) \n",
    "    cvll_MAE_list.append(cvll_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Models\n",
    "cvrf_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvrf_MAE = model_MAE.cvRandomForest(df, target, 4) \n",
    "    cvrf_MAE_list.append(cvrf_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweedie Regressor Models\n",
    "cvtw_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvtw_MAE = model_MAE.cvTweedie(df, target, 1.25, .25)\n",
    "    cvtw_MAE_list.append(cvtw_MAE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Models\n",
    "cvSVRrbf_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvSVRrbf_MAE = model_MAE.cvSVR(df, target, 'rbf')\n",
    "    cvSVRrbf_MAE_list.append(cvSVRrbf_MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Models\n",
    "cvSVRlinear_MAE_list = []\n",
    "for df in df2test:\n",
    "    cvSVRlinear_MAE = model_MAE.cvSVR(df, target, 'linear')\n",
    "    cvSVRlinear_MAE_list.append(cvSVRlinear_MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for results of all train models\n",
    "df_list = ['rank_svi_only', 'top4', 'total_all_flags_only', 'summary_flags', 'not_summary_flags', \n",
    "           'all_features', 'raw_svi_only', 'top10', 'svi_features', 'Rlist']\n",
    "\n",
    "results = pd.DataFrame(df_list, columns=['Features'])\n",
    "results['Base_mean_MAE'] = mean_baseMAE\n",
    "results['LinearRegression_MAE'] = cvlm_MAE_list\n",
    "results['LassoLars_MAE'] = cvll_MAE_list\n",
    "results['Tweedie_MAE'] = cvtw_MAE_list\n",
    "results['RandomForest_MAE'] = cvrf_MAE_list\n",
    "results['SVR_rbf_MAE'] = cvSVRrbf_MAE_list\n",
    "results['SVR_linear_MAE'] = cvSVRlinear_MAE_list\n",
    "results.sort_values('LinearRegression_MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataframe with Top10 features as identified by RFE as that is the best performing model\n",
    "X_test_top10 = X_test_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr', 'rank_svi_scaled', \n",
    "                          'f_soci_total_scaled', 'f_pov_soci', 'ep_pov_scaled', 'raw_svi', 'f_age17_comp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear Regression with Top4 features on train dataset, then use that model to predict test values\n",
    "TWtestMAE, modelTW = model_MAE.tweedie_test(X_top10, y_train, X_test_top10, y_test, 1.5, .5)\n",
    "TWtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRtestMAE, modelLR = model_MAE.linear_test(X_top10, y_train, X_test_top10, y_test)\n",
    "LRtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLtestMAE, modelLL = model_MAE.lasso_lars_test(X_top10, y_train, X_test_top10, y_test)\n",
    "LLtestMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways\n",
    "\n",
    "- the Top10 performed best on train, but appear to be overfit\n",
    "- to reduce overfitting will run the Top4 feature model instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataframe with only Top4 features as identified by RFE as that is the best performing model\n",
    "X_test_top4 = X_test_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit Linear Regression with Top4 features on train dataset, then use that model to predict test values\n",
    "TWtestMAE, modelTW = model_MAE.tweedie_test(X_top4, y_train, X_test_top4, y_test, 1.5, .5)\n",
    "TWtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRtestMAE, modelLR = model_MAE.linear_test(X_top4, y_train, X_test_top4, y_test)\n",
    "LRtestMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLtestMAE, modelLL = model_MAE.lasso_lars_test(X_top4, y_train, X_test_top4, y_test)\n",
    "LLtestMAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "1. Our models successfully beat the baseline.\n",
    "2. Using the top 4 features (as selected by RFE) Tweedie Regression returned a lower MAE (767 vs 973), Linear Regression returned a lower MAE (785 vs 973) than the baseline, and LassoLars returned a lower MAE (780 vs 973) than the baseline model.\n",
    "3. Due to this lower error measurement than baseline, we feel confident that our models can be used to effectively predict the graduated need for resources in specific areas in the event of another pandemic.\n",
    "4. The Tweedie regression model is a 21% improvement over baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweedie regression Summary:\n",
    "\n",
    "Tweedie is a generalized Linear Model with a Tweedie distribution. The power parameter adjusted the distribution and the alpha parameter determines the regularization strength.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweedie Results table:\n",
    "tw_result = pd.DataFrame()\n",
    "x_train_columns = X_test_top4.columns.tolist()\n",
    "tw_result['features'] = x_train_columns\n",
    "tw_result['coefs'] = modelTW.coef_\n",
    "tw_result['abs_coefs'] = abs(modelTW.coef_)\n",
    "tw_result.sort_values(by = 'abs_coefs', ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strengths\n",
    "\n",
    "- The model demonstrated that the SVI does a good job of predicting in San Antonio the areas that were most at risk from the COVID infections. Interestingly enough, those areas most at risk from natural disasters (such as hurricanes, fires, and other acts of nature) the communities needing resources in response to a pandemic within San Antonio appear to be highly correlated to the overall SVI score.\n",
    "- Looking inside the Index itself and reviewing the component parts, we discovered that socioeconomic \"flags\" or components tended to be a stronger correlation than other types of components of the overall Social Vulnerability Index.\n",
    "\n",
    "\n",
    "#### Weaknesses\n",
    "\n",
    "- There is no consensus in research literature as to which components of the SVI have the strongest correlation to health risks or outcomes. There are some demographic groups requiring careful interpretation of the results due to their unique characteristics.\n",
    "- These models are not intended in any way to be presented as predictions of infection; the medical reasons for COVID transmission are still as yet undetermined, and would require a vastly more complex model than is presented here. The purpose of this model was to measure and predict those areas most in need of help and response from communities and local officials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in classification datasets with new y variable\n",
    "class_df, class_train_exp, class_X_train_scaled, class_y_train, class_X_test_scaled, class_y_test = wrangle.wrangle_data_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only raw svi score\n",
    "cX_raw_svi = class_X_train_scaled[['raw_svi']]\n",
    "# binned svi score by CDC range category = 1st ranked\n",
    "cX_rank_svi_only = class_X_train_scaled[['rank_svi_scaled']]\n",
    "# top 4 ranked features\n",
    "cX_top4 = class_X_train_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr']]\n",
    "# only the summary of the flags = 19th ranked\n",
    "cX_all_flags_only = class_X_train_scaled[['all_flags_total_scaled']]\n",
    "# only summary flags, should be the same as all flags total? = 5th, 12th, 15th, 21st\n",
    "cX_summary_flags = class_X_train_scaled[['f_comp_total_scaled', 'f_soci_total_scaled', 'f_status_total_scaled', 'f_trans_total_scaled']]\n",
    "# all individual flags\n",
    "cX_not_summary_flags = class_X_train_scaled[['f_nohsdp_soci', 'f_minrty_status', 'f_groupq_trans', 'f_unemp_soci', \n",
    "                                     'f_disabl_comp', 'f_noveh_trans', 'f_mobile_trans', 'f_age65_comp', \n",
    "                                     'f_age17_comp', 'f_pov_soci', 'f_limeng_status', 'f_crowd_trans', \n",
    "                                      'f_pci_soci', 'f_sngpnt_comp', 'f_munit_trans']]\n",
    "# top 10 by RFE\n",
    "cX_top10 = class_X_train_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr', 'rank_svi_scaled', \n",
    "                          'f_soci_total_scaled', 'f_pov_soci', 'ep_pov_scaled', 'raw_svi', 'f_age17_comp']]\n",
    "# engineered features only\n",
    "cX_svifeatures = class_X_train_scaled[['rising', 'falling', 'delta', 'avg3yr', 'r_soci_rise', 'r_comp_rise', \n",
    "                                'r_status_rise', 'r_trans_rise', 'r_soci_fall', 'r_comp_fall', 'r_status_fall', 'r_trans_fall']]\n",
    "cX_Rlist = class_X_train_scaled[['rank_svi_scaled', 'rising', 'falling', 'delta', 'avg3yr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for loop\n",
    "cdf2test = [cX_rank_svi_only, cX_top4, cX_all_flags_only, cX_summary_flags, cX_not_summary_flags, class_X_train_scaled, \n",
    "           cX_raw_svi, cX_top10, cX_svifeatures, cX_Rlist]\n",
    "ctarget = class_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_y_train.rank_cases.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model we have chosen is the most commonly occuring case bin, rank 3, at 48.7%. \n",
    "\n",
    "- This means, if our model returns an accuracy that is > 48.7%, our model is better at predicting COVID case count than simply choosing the most commonly occuring bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.tract_cases_per_100k.plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification.random_forest_class(cX_raw_svi, ctarget, max_depth = 4, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for loop\n",
    "crf2test = [\n",
    "            cX_rank_svi_only, \n",
    "            cX_top4, \n",
    "            cX_all_flags_only, \n",
    "            cX_summary_flags, \n",
    "            cX_not_summary_flags, \n",
    "            class_X_train_scaled, \n",
    "            cX_raw_svi, \n",
    "            cX_top10, \n",
    "            cX_svifeatures, \n",
    "            cX_Rlist\n",
    "           ]\n",
    "# target var:\n",
    "ctarget = class_y_train\n",
    "\n",
    "\n",
    "# Random Forest Models Classification Loop\n",
    "cvrf_class_list = []\n",
    "for df in crf2test:\n",
    "    cvrf_class = model_classification.random_forest_class(df, ctarget, max_depth = 3, n_estimators = 75) \n",
    "    cvrf_class_list.append(cvrf_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for loop\n",
    "crf2test = [\n",
    "            cX_rank_svi_only, \n",
    "            cX_top4, \n",
    "            cX_all_flags_only, \n",
    "            cX_summary_flags, \n",
    "            cX_not_summary_flags, \n",
    "            class_X_train_scaled, \n",
    "            cX_raw_svi, \n",
    "            cX_top10, \n",
    "            cX_svifeatures, \n",
    "            cX_Rlist\n",
    "           ]\n",
    "# target var:\n",
    "ctarget = class_y_train\n",
    "\n",
    "\n",
    "# Random Forest Models Classification Loop\n",
    "cvrf_class_list = []\n",
    "for df in crf2test:\n",
    "    cvrf_class = model_classification.random_forest_class(df, ctarget, max_depth = 2, n_estimators = 200) \n",
    "    cvrf_class_list.append(cvrf_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "\n",
    "- The best set of features for the Random Forest model was the Top 4 features as selected by RFE, which include the average change of the SVI in a given area over 3 years, the amount changed, and the engeineerd feature which measures if the SVI score was falling for a particular sub-group. These features together with the overall total number of features within the socioecomomic theme created the best model within the Random Forest training. \n",
    "- Overall, most of these models came close to or best the baseline.\n",
    "- The best RF model beat the baseline by 14%, 62% vs 48%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification.knn_classification(cX_rank_svi_only, class_y_train, n_neighbors=5, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for loop\n",
    "cknn2test = [\n",
    "            cX_rank_svi_only, \n",
    "            cX_top4, \n",
    "            cX_all_flags_only, \n",
    "            cX_summary_flags, \n",
    "            cX_not_summary_flags, \n",
    "            class_X_train_scaled, \n",
    "            cX_raw_svi, \n",
    "            cX_top10, \n",
    "            cX_svifeatures, \n",
    "            cX_Rlist\n",
    "           ]\n",
    "# target var:\n",
    "cknn_target = class_y_train\n",
    "\n",
    "\n",
    "# KNN Models Classification Loop\n",
    "cvknn_class_list = []\n",
    "for df in cknn2test:\n",
    "    cvknn_class = model_classification.knn_classification(df, cknn_target, n_neighbors=5, cv = 10) \n",
    "    cvknn_class_list.append(cvknn_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "\n",
    "- Best KNN model on our train dataset was the model using the top 4 features as defined by FRE. The accuracy of this model was 56%.\n",
    "- This still beat the baseline by 8%, but since it wasn't as high a score as Random Forest, will will use RF in the test stage.\n",
    "- We selected a k of 5, which yielded the best results from the limited dataset that we had. Still, our models were able to beat the baseline accuracy with all but one set of features (Which interestingly, was the raw SVI score itself). \n",
    "- This leads us to believe that there are very specific demographic realities within the San Antonio community that lends itself to more accurately being measuring by SVI than other measurement techniques.\n",
    "- However, based on the lower score, we opted to take Random Forest to the next step of testing on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_top_4_class = class_X_test_scaled[['spl_theme1_scaled', 'r_status_fall', 'delta', 'avg3yr']]\n",
    "raw_test_svi = class_X_test_scaled[['rank_svi_scaled']] \n",
    "class_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification.rf_test_class(cX_rank_svi_only, ctarget, raw_test_svi, class_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modeling Summary\n",
    "- In this classification modeling phase, we ran a series of classification models using the Random Forest and KNN algorithmns which sought to use SVI components as features in the models to predict the severity of COVID cases based on our contructed rankings of case counts: Low, Low-Moderate, Moderate-High, and High bins.\n",
    "- What we found is the most useful features for our classification models were also similar to the features we found as useful in regression modeling.\n",
    "- Our best model, using the Random Forest algorithmn and using the top 4 RFE features yielded an accuracy result of **55%**, which is an improvement over the baseline of **7%**, (or an increase in accuracy of 14.5%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps: What Can We Do Now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is San Antonio different from other cities?\n",
    "\n",
    "\n",
    "- San Antonio is very different from Dallas\n",
    "- SVI and features do seem to correlate closely with high case rates in San Antonio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- SVI trend for the county\n",
    "    - is rising? is declining? \n",
    "    - delta of SVI change year over year?\n",
    "    - std dev of SVI?\n",
    "\n",
    "- This is an area for possible further exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
